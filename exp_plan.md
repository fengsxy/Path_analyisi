# LIFT 模型性能差距分析：实验计划

## 背景

### 当前结果 (30 Epoch, ~58M 参数)
| 模型 | FID ↓ |
|------|-------|
| **Baseline (单尺度)** | **78.83** |
| LIFT DP 64×64 | 101.53 |
| LIFT DP Total | 109.20 |
| LIFT Diagonal | 116.14 |

### 核心问题
> 为什么 LIFT 模型在相同参数量下，FID 比 Baseline 差 22+ 点？

### 原始假设
"32×32 只是加了一个通道，模型不应该变差，至少保持一样"

但实际结果与假设矛盾，需要找到解释。

---

## 候选假设

| ID | 假设 | 解释 |
|----|------|------|
| H1 | **多任务损失冲突** | loss_64 和 loss_32 的梯度方向冲突，优化困难 |
| H2 | **训练空间过大** | 独立时间步导致 (t_64, t_32) 组合空间从 1K 扩展到 1M |
| H3 | **噪声输入有害** | 噪声 32×32 输入增加了学习难度，而非提供有用信息 |
| H4 | **32×32 无实际贡献** | 生成时 32×32 分支没有提供有用的结构信息 |

---

## 实验设计

### 实验 1: 只优化 64×64 损失 (验证 H1)

**目的**: 测试 loss_32 是否在拖后腿

**修改**:
```python
# 原始
loss = loss_64 + loss_32

# 修改
loss = loss_64  # 只优化 64×64
```

**训练设置**:
- 模型结构: 保持不变 (仍然输出 noise_pred_64 和 noise_pred_32)
- 输入: 保持不变 (x_64, x_32, t_64, t_32)
- 损失: 只用 loss_64
- Epochs: 30
- 其他参数: 与原始 LIFT 相同

**预期结果**:
- 如果 FID 显著提升 → H1 成立，多任务损失是问题
- 如果 FID 无变化 → H1 不成立

**输出文件**: `checkpoints/lift_loss64_only.pth`

---

### 实验 2: 对角线时间步训练 (验证 H2)

**目的**: 测试独立时间步是否导致训练空间过大

**修改**:
```python
# 原始
t_64 = torch.randint(0, 1000, (batch_size,))
t_32 = torch.randint(0, 1000, (batch_size,))  # 独立采样

# 修改
t_64 = torch.randint(0, 1000, (batch_size,))
t_32 = t_64  # 强制相同
```

**训练设置**:
- 模型结构: 保持不变
- 输入: x_64, x_32, t, t (两个时间步相同)
- 损失: loss_64 + loss_32
- Epochs: 30
- 其他参数: 与原始 LIFT 相同

**预期结果**:
- 如果 FID 显著提升 → H2 成立，训练空间过大是问题
- 如果 FID 无变化 → H2 不成立

**注意**: 此模型只能用 diagonal 路径生成

**输出文件**: `checkpoints/lift_diagonal_train.pth`

---

### 实验 3: 干净 32×32 输入训练 (验证 H3)

**目的**: 测试噪声 32×32 输入是否有害

**修改**:
```python
# 原始
x_32_noisy = sqrt(alpha_bar) * x_32 + sqrt(1 - alpha_bar) * noise_32

# 修改
x_32_clean = x_32  # 始终使用干净的 32×32
t_32 = 0  # 时间步设为 0
```

**训练设置**:
- 模型结构: 保持不变
- 输入: x_64_noisy, x_32_clean, t_64, 0
- 损失: 只用 loss_64 (因为 x_32 是干净的，没有噪声可预测)
- Epochs: 30
- 其他参数: 与原始 LIFT 相同

**预期结果**:
- 如果 FID 显著提升 → H3 成立，噪声输入是问题
- 如果 FID 无变化 → H3 不成立

**生成方式**:
- 先用独立模型生成 32×32
- 或使用 64×64 下采样作为 32×32 guidance

**输出文件**: `checkpoints/lift_clean32_train.pth`

---

### 实验 4: 随机 32×32 生成测试 (验证 H4)

**目的**: 测试生成时 32×32 是否真的有用

**修改**: 不需要重新训练，使用现有 LIFT 模型

**生成方式**:
```python
# 原始 diagonal 生成
x_64, x_32 = denoise_step(x_64, x_32, t, t)

# 修改: 32×32 保持随机噪声
x_64, _ = denoise_step(x_64, random_noise, t, t)
# 或者: 32×32 不更新
x_64, _ = denoise_step(x_64, x_32_fixed, t, t)
```

**测试设置**:
- 模型: 使用现有 `lift_30ep.pth`
- 生成: 1000 张图片
- 对比:
  - A: 正常 diagonal 生成 (两个尺度都去噪)
  - B: 32×32 保持随机噪声
  - C: 32×32 固定为某个噪声不更新

**预期结果**:
- 如果 B/C 的 FID ≈ A → H4 成立，32×32 没有实际贡献
- 如果 B/C 的 FID >> A → H4 不成立，32×32 确实有帮助

**输出目录**:
- `results/fid_lift_random32/`
- `results/fid_lift_fixed32/`

---

## 实验优先级

| 优先级 | 实验 | 原因 |
|--------|------|------|
| 1 | 实验 4 | 不需要训练，最快验证 |
| 2 | 实验 1 | 训练改动最小 |
| 3 | 实验 2 | 验证核心假设 |
| 4 | 实验 3 | 改动较大，需要配合生成策略 |

---

## 执行计划

### Phase 1: 快速验证 (实验 4)
```bash
# 使用现有模型，只需修改生成代码
python generate_for_fid.py --mode random32 ...
python generate_for_fid.py --mode fixed32 ...
```
预计时间: 30 分钟

### Phase 2: 消融训练 (实验 1, 2)
```bash
# 并行训练两个消融模型
./train_ablation.sh
```
预计时间: 40 分钟 (30 epochs)

### Phase 3: 条件训练 (实验 3)
```bash
# 需要额外的生成策略
./train_clean32.sh
```
预计时间: 40 分钟 + 生成策略开发

---

## 预期结论矩阵

| 实验 1 | 实验 2 | 实验 3 | 实验 4 | 结论 |
|--------|--------|--------|--------|------|
| ✓ 提升 | - | - | - | 多任务损失是主要问题 |
| - | ✓ 提升 | - | - | 训练空间过大是主要问题 |
| - | - | ✓ 提升 | - | 噪声输入是主要问题 |
| - | - | - | ✓ 无差 | 32×32 分支无实际贡献 |
| ✓ | ✓ | - | - | 多因素共同作用 |
| - | - | - | ✗ 变差 | 32×32 确实有帮助，问题在训练 |

---

## 文件结构

```
simple_diffusion_clean/
├── exp_plan.md                    # 本文档
├── train_ablation.sh              # 消融实验训练脚本
├── train_loss64_only.py           # 实验 1 训练代码
├── train_diagonal.py              # 实验 2 训练代码
├── train_clean32.py               # 实验 3 训练代码
├── generate_ablation.py           # 实验 4 生成代码
└── results/
    ├── fid_lift_loss64_only/      # 实验 1 生成图片
    ├── fid_lift_diagonal_train/   # 实验 2 生成图片
    ├── fid_lift_clean32/          # 实验 3 生成图片
    ├── fid_lift_random32/         # 实验 4a 生成图片
    └── fid_lift_fixed32/          # 实验 4b 生成图片
```

---

## 备注

- 所有实验使用相同的随机种子以保证可比性
- FID 计算使用相同的 1000 张真实图片作为参考
- 100 epoch 训练结果待补充，可能影响实验设计
